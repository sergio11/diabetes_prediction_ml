{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Diabetes Diagnosis Using Machine Learning: A Comprehensive Analysis of Patient Data\n",
        "\n",
        "Diabetes is a chronic disease that affects millions of people worldwide, making early detection crucial for better management and treatment. In this analysis, we aim to leverage machine learning techniques to predict whether a patient has diabetes based on various medical attributes. The dataset used for this task comes from the **National Institute of Diabetes and Digestive and Kidney Diseases**, specifically focusing on female patients aged 21 and older of Pima Indian descent.\n",
        "\n",
        "By exploring this dataset, we will build a predictive model that can diagnose diabetes with high accuracy, using several diagnostic measurements including glucose levels, blood pressure, BMI, and others. The ultimate goal is to create a robust machine learning model capable of predicting the presence of diabetes, offering valuable insights for healthcare professionals and patients alike.\n",
        "\n",
        "## About the Dataset\n",
        "\n",
        "This dataset originates from the **National Institute of Diabetes and Digestive and Kidney Diseases**. The objective is to diagnostically predict whether a patient has diabetes based on certain diagnostic measurements included in the dataset. The data specifically focuses on female patients aged 21 years and older of Pima Indian heritage. Several constraints were placed on the selection of the instances from a larger database.\n",
        "\n",
        "The dataset contains both independent medical predictor variables and one target variable, **Outcome**, which indicates whether a patient has diabetes or not.\n",
        "\n",
        "## Variables\n",
        "\n",
        "- **Pregnancies**: Number of pregnancies.\n",
        "- **Glucose**: 2-hour plasma glucose concentration in the oral glucose tolerance test.\n",
        "- **Blood Pressure**: Blood pressure (mm Hg).\n",
        "- **Skin Thickness**: Skin thickness.\n",
        "- **Insulin**: 2-hour serum insulin (mu U/ml).\n",
        "- **DiabetesPedigreeFunction**: Diabetes pedigree function.\n",
        "- **BMI**: Body Mass Index.\n",
        "- **Age**: Age (in years).\n",
        "- **Outcome**: Diabetes diagnosis (1 = positive, 0 = negative).\n",
        "\n",
        "## Techniques and Tools Used\n",
        "\n",
        "This analysis will employ several tools and techniques, including:\n",
        "\n",
        "- **Exploratory Data Analysis (EDA)**: To understand the distribution and relationships between variables.\n",
        "- **Correlation Analysis**: To examine how variables are related to one another.\n",
        "- **Feature Engineering**: To improve model performance by creating new features and modifying existing ones.\n",
        "- **Data Preprocessing**: Including handling missing values, outliers, and encoding categorical variables.\n",
        "- **Model Building**: The following machine learning models will be utilized:\n",
        "  - **RandomForestClassifier**\n",
        "  - **Logistic Regression**\n",
        "  - **K-Nearest Neighbors (KNN)**\n",
        "  - **Support Vector Classifier (SVC)**\n",
        "  - **Decision Tree Classifier**\n",
        "  - **AdaBoost Classifier**\n",
        "  - **Gradient Boosting Classifier**\n",
        "  - **XGBoost Classifier**\n",
        "  - **LightGBM Classifier**\n",
        "  \n",
        "- **Hyperparameter Optimization**: Using techniques like grid search and random search to find the optimal settings for the models.\n",
        "- **Model Evaluation**: Comparing the performance of various models using metrics like accuracy, precision, recall, and F1 score.\n",
        "- **Visualization**: To display model performance and feature importance.\n",
        "\n",
        "The overall goal is to build a predictive model that can effectively diagnose diabetes based on the provided medical features.\n"
      ],
      "metadata": {
        "id": "gP4bbiq6-rZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Tools\n",
        "\n",
        "To efficiently analyze the dataset and build a machine learning model for diabetes prediction, we utilize a variety of libraries and tools, each serving a specific purpose:\n",
        "\n",
        "### ðŸ”¹ Data Handling & Manipulation  \n",
        "- **NumPy** (`numpy`): Efficient numerical operations.  \n",
        "- **Pandas** (`pandas`): Data manipulation and analysis.  \n",
        "\n",
        "### ðŸ”¹ Data Visualization  \n",
        "- **Matplotlib** (`matplotlib.pyplot`): Basic plotting and visualizations.  \n",
        "- **Seaborn** (`seaborn`): Statistical data visualization.  \n",
        "- **Plotly** (`plotly.express`, `plotly.graph_objects`): Interactive and advanced visualizations.  \n",
        "\n",
        "### ðŸ”¹ Machine Learning & Model Evaluation  \n",
        "- **Scikit-learn** (`sklearn`):  \n",
        "  - Model training: `RandomForestClassifier`, `LogisticRegression`, `KNeighborsClassifier`, `SVC`, `DecisionTreeClassifier`, `AdaBoostClassifier`, `GradientBoostingClassifier`.  \n",
        "  - Model evaluation: `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_auc_score`.  \n",
        "  - Hyperparameter tuning: `GridSearchCV`, `cross_validate`.  \n",
        "  - Data preprocessing: `StandardScaler`, `RobustScaler`, `LabelEncoder`, `KNNImputer`.  \n",
        "  - Train-test splitting: `train_test_split`.  \n",
        "\n",
        "- **XGBoost** (`xgboost`): Optimized gradient boosting for classification.  \n",
        "- **LightGBM** (`lightgbm`): High-performance gradient boosting.  \n",
        "\n",
        "### ðŸ”¹ Miscellaneous  \n",
        "- **Itertools** (`itertools`): Advanced iteration tools.  \n",
        "- **Warnings** (`warnings`): Suppressing unnecessary warnings for a cleaner output.  \n",
        "\n",
        "Each of these tools plays a crucial role in preparing, visualizing, modeling, and evaluating our dataset for effective diabetes prediction. ðŸš€\n"
      ],
      "metadata": {
        "id": "I1WBchtOcqTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import itertools\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgSWxz30cqpv",
        "outputId": "13529da7-2802-4cb0-c6db-f48d6dd4d5a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring Pandas Display Options\n",
        "\n",
        "To improve the readability of our dataset when displayed in the notebook, we configure **Pandas display options** as follows:  \n",
        "\n",
        "- **`display.max_columns = None`** â†’ Ensures all columns are displayed without truncation.  \n",
        "- **`display.width = None`** â†’ Automatically adjusts the display width to fit the notebook output.  \n",
        "- **`display.max_rows = 20`** â†’ Limits the number of displayed rows to 20 for better readability.  \n",
        "- **`display.float_format = lambda x: '%.3f' % x`** â†’ Formats floating-point numbers to 3 decimal places for consistency.  \n",
        "\n",
        "These settings help us visualize the dataset more effectively without losing important details.\n"
      ],
      "metadata": {
        "id": "uESWaSjgdCIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ],
      "metadata": {
        "id": "0nwJHy4KdCSq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset  \n",
        "\n",
        "The diabetes dataset is imported using Pandas, allowing us to structure and manipulate the data efficiently. This dataset will serve as the foundation for exploratory data analysis (EDA) and machine learning modeling.  \n",
        "\n",
        "By loading the data into a DataFrame, we can seamlessly perform operations such as filtering, transformation, and visualization, facilitating a deeper understanding of the relationships between variables and their impact on diabetes prediction.  "
      ],
      "metadata": {
        "id": "QrzZoI4-gRRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"diabetes.csv\")"
      ],
      "metadata": {
        "id": "kA9PTHEphOo-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "Exploratory Data Analysis (EDA) is a crucial phase in any data analysis project. In this stage, our goal is to better understand the dataset, explore the relationships between variables, and detect possible patterns, trends, and anomalies.  \n",
        "\n",
        "During EDA, we focus on identifying:\n",
        "\n",
        "- The **structure** and **content** of the dataset (size, variable types).\n",
        "- **Missing values** and their impact on the analysis.\n",
        "- The **distributions** of numerical and categorical variables.\n",
        "- **Correlations** between variables that might influence the predictive model.\n",
        "\n",
        "EDA provides the initial insights needed to make informed decisions about how to proceed with data preparation and model construction. It is essential to ensure that the dataset's quality is suitable for further analysis.\n",
        "\n",
        "In this project, we will use various tools and methods to explore our dataset and gain a better understanding of the relationships between the variables.  "
      ],
      "metadata": {
        "id": "rLCshvZrhXh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **`check_df()`** function is designed to perform a quick preliminary analysis of our dataset to provide an organized overview. When running this function, several key metrics are presented that will help us evaluate the data's quality and characteristics.\n",
        "\n",
        "#### Description of Each Section:\n",
        "\n",
        "- **Shape**: Displays the number of rows and columns in the DataFrame. This gives us an idea of the dataset's size.\n",
        "\n",
        "- **Data Types**: Shows the data types of each column (e.g., integer, float, object). This is important to ensure the data is in the correct format for further analysis.\n",
        "\n",
        "- **Head and Tail**: Displays the first and last few rows of the dataset. This allows us to quickly inspect the first and last entries to identify potential inconsistencies or patterns.\n",
        "\n",
        "- **Missing Values**: Calculates and shows the number of missing (NaN) values in each column. Identifying missing values is essential for deciding how to handle them (e.g., removal, imputation, etc.).\n",
        "\n",
        "- **Unique Values**: Shows the number of unique values in each column. This helps us understand the diversity of data in each variable, especially for categorical columns.\n",
        "\n",
        "- **Summary Statistics**: Provides key descriptive statistics such as mean, standard deviation, min, max, and percentiles. This is useful for understanding the distribution of numerical variables.\n",
        "\n",
        "- **Quantiles**: Displays selected percentiles (0, 5, 50, 95, 99, 100) of numerical columns. This helps identify the spread of data and potential outliers.\n",
        "\n",
        "By running this function at the start of the analysis, we gain a general understanding of the dataset, allowing us to make informed decisions about how to handle missing values, outliers, and other critical aspects before moving forward with modeling.  \n"
      ],
      "metadata": {
        "id": "DDrmYCjOhcPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_df(dataframe, head=5):\n",
        "    \"\"\"\n",
        "    Provides an overview of a Pandas DataFrame, displaying key statistics and structure.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame to analyze.\n",
        "    head (int): Number of rows to display in the head() and tail() sections.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    print(\"##################### Shape #####################\")\n",
        "    print(f\"Rows: {dataframe.shape[0]}, Columns: {dataframe.shape[1]}\\n\")\n",
        "\n",
        "    print(\"##################### Data Types #####################\")\n",
        "    print(dataframe.dtypes, \"\\n\")\n",
        "\n",
        "    print(\"##################### Head #####################\")\n",
        "    print(dataframe.head(head), \"\\n\")\n",
        "\n",
        "    print(\"##################### Tail #####################\")\n",
        "    print(dataframe.tail(head), \"\\n\")\n",
        "\n",
        "    print(\"##################### Missing Values #####################\")\n",
        "    na_counts = dataframe.isnull().sum()\n",
        "    print(na_counts[na_counts > 0] if na_counts.sum() > 0 else \"No missing values\", \"\\n\")\n",
        "\n",
        "    print(\"##################### Unique Values #####################\")\n",
        "    print(dataframe.nunique(), \"\\n\")\n",
        "\n",
        "    print(\"##################### Summary Statistics #####################\")\n",
        "    print(dataframe.describe().T, \"\\n\")\n",
        "\n",
        "    print(\"##################### Quantiles #####################\")\n",
        "    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n",
        "\n",
        "# Execute function\n",
        "check_df(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqquIq15hCAG",
        "outputId": "79f60894-bf3d-48ea-930e-90acdc822061"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################### Shape #####################\n",
            "Rows: 768, Columns: 9\n",
            "\n",
            "##################### Data Types #####################\n",
            "Pregnancies                   int64\n",
            "Glucose                       int64\n",
            "BloodPressure                 int64\n",
            "SkinThickness                 int64\n",
            "Insulin                       int64\n",
            "BMI                         float64\n",
            "DiabetesPedigreeFunction    float64\n",
            "Age                           int64\n",
            "Outcome                       int64\n",
            "dtype: object \n",
            "\n",
            "##################### Head #####################\n",
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin    BMI  DiabetesPedigreeFunction  \\\n",
            "0            6      148             72             35        0 33.600                     0.627   \n",
            "1            1       85             66             29        0 26.600                     0.351   \n",
            "2            8      183             64              0        0 23.300                     0.672   \n",
            "3            1       89             66             23       94 28.100                     0.167   \n",
            "4            0      137             40             35      168 43.100                     2.288   \n",
            "\n",
            "   Age  Outcome  \n",
            "0   50        1  \n",
            "1   31        0  \n",
            "2   32        1  \n",
            "3   21        0  \n",
            "4   33        1   \n",
            "\n",
            "##################### Tail #####################\n",
            "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin    BMI  DiabetesPedigreeFunction  \\\n",
            "763           10      101             76             48      180 32.900                     0.171   \n",
            "764            2      122             70             27        0 36.800                     0.340   \n",
            "765            5      121             72             23      112 26.200                     0.245   \n",
            "766            1      126             60              0        0 30.100                     0.349   \n",
            "767            1       93             70             31        0 30.400                     0.315   \n",
            "\n",
            "     Age  Outcome  \n",
            "763   63        0  \n",
            "764   27        0  \n",
            "765   30        0  \n",
            "766   47        1  \n",
            "767   23        0   \n",
            "\n",
            "##################### Missing Values #####################\n",
            "No missing values \n",
            "\n",
            "##################### Unique Values #####################\n",
            "Pregnancies                  17\n",
            "Glucose                     136\n",
            "BloodPressure                47\n",
            "SkinThickness                51\n",
            "Insulin                     186\n",
            "BMI                         248\n",
            "DiabetesPedigreeFunction    517\n",
            "Age                          52\n",
            "Outcome                       2\n",
            "dtype: int64 \n",
            "\n",
            "##################### Summary Statistics #####################\n",
            "                           count    mean     std    min    25%     50%     75%     max\n",
            "Pregnancies              768.000   3.845   3.370  0.000  1.000   3.000   6.000  17.000\n",
            "Glucose                  768.000 120.895  31.973  0.000 99.000 117.000 140.250 199.000\n",
            "BloodPressure            768.000  69.105  19.356  0.000 62.000  72.000  80.000 122.000\n",
            "SkinThickness            768.000  20.536  15.952  0.000  0.000  23.000  32.000  99.000\n",
            "Insulin                  768.000  79.799 115.244  0.000  0.000  30.500 127.250 846.000\n",
            "BMI                      768.000  31.993   7.884  0.000 27.300  32.000  36.600  67.100\n",
            "DiabetesPedigreeFunction 768.000   0.472   0.331  0.078  0.244   0.372   0.626   2.420\n",
            "Age                      768.000  33.241  11.760 21.000 24.000  29.000  41.000  81.000\n",
            "Outcome                  768.000   0.349   0.477  0.000  0.000   0.000   1.000   1.000 \n",
            "\n",
            "##################### Quantiles #####################\n",
            "                          0.000  0.050   0.500   0.950   0.990   1.000\n",
            "Pregnancies               0.000  0.000   3.000  10.000  13.000  17.000\n",
            "Glucose                   0.000 79.000 117.000 181.000 196.000 199.000\n",
            "BloodPressure             0.000 38.700  72.000  90.000 106.000 122.000\n",
            "SkinThickness             0.000  0.000  23.000  44.000  51.330  99.000\n",
            "Insulin                   0.000  0.000  30.500 293.000 519.900 846.000\n",
            "BMI                       0.000 21.800  32.000  44.395  50.759  67.100\n",
            "DiabetesPedigreeFunction  0.078  0.140   0.372   1.133   1.698   2.420\n",
            "Age                      21.000 21.000  29.000  58.000  67.000  81.000\n",
            "Outcome                   0.000  0.000   0.000   1.000   1.000   1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"diabetes.csv\")"
      ],
      "metadata": {
        "id": "tq13kkmrgRdz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identifying and Classifying Numeric and Categorical Variables\n",
        "\n",
        "In any data analysis or machine learning project, one of the first steps is to understand the types of variables in the dataset. This is crucial because the way we handle variables depends on whether they are numerical or categorical.\n",
        "\n",
        "### Types of Variables\n",
        "1. **Numerical Variables**:\n",
        "   - These are variables that represent quantifiable values and can be discrete (like the number of items) or continuous (like height, weight, or age).\n",
        "   - Examples include: `Age`, `Blood Pressure`, `BMI`, `Glucose`.\n",
        "\n",
        "2. **Categorical Variables**:\n",
        "   - These variables represent categories or groups. They usually take on a limited, fixed number of values, and the categories might not have a specific order.\n",
        "   - Examples include: `Gender`, `Outcome` (diabetes positive/negative), `SkinThickness` (may be treated as categorical depending on analysis).\n",
        "\n",
        "### Importance of Identifying Variable Types\n",
        "Correctly identifying the type of each variable helps us make decisions about:\n",
        "- **Data Preprocessing**: Numerical variables may need scaling or normalization, while categorical variables might require encoding techniques like One-Hot Encoding or Label Encoding.\n",
        "- **Analysis & Modeling**: Some machine learning models or statistical tests require different treatments for numerical vs categorical variables.\n",
        "\n",
        "### Categorizing Variables\n",
        "To classify the variables into numerical and categorical, we typically rely on:\n",
        "- **Data Type**: Checking the data type of each column (e.g., integer, float, object).\n",
        "- **Unique Value Count**: For numerical variables with few unique values (e.g., binary or limited range), it might make sense to treat them as categorical.\n",
        "- **Business Context**: Sometimes, a variable that is numerical might be better treated as categorical based on the domain knowledge or the analysis objective.\n",
        "\n",
        "### Process Overview\n",
        "1. **Identify Categorical Variables**: These variables are usually of type \"object\" or string, but sometimes numerical columns with a small number of unique values can also be treated as categorical.\n",
        "2. **Identify Numerical Variables**: These are variables of type integer or float that contain continuous or discrete data. However, numerical variables with a very limited range of unique values may need to be categorized.\n",
        "3. **Distinguish Special Cases**: Some variables may have characteristics that allow them to belong to both categories, such as \"numerical but categorical\" or \"categorical but cardinal.\" These cases often require additional scrutiny.\n",
        "\n",
        "### Benefits of Capturing Variable Types\n",
        "- **Efficient Data Processing**: By accurately categorizing variables, we can efficiently preprocess data, apply the correct transformations, and choose the right algorithms for analysis.\n",
        "- **Improved Model Accuracy**: Knowing the nature of the data ensures the right model is selected, and appropriate techniques are applied for feature engineering, thus improving the performance of the machine learning model.\n",
        "\n",
        "In summary, identifying and categorizing numeric and categorical variables is an essential first step in the data exploration process. It lays the foundation for proper data handling, effective analysis, and better decision-making in model building."
      ],
      "metadata": {
        "id": "DjeapX4diPv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
        "    \"\"\"\n",
        "    Classify columns in a dataframe into categorical and numerical columns\n",
        "    based on their characteristics such as data type and number of unique values.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame to analyze.\n",
        "    cat_th (int): Threshold for categorizing columns with fewer unique values as categorical.\n",
        "    car_th (int): Threshold for categorizing columns with more unique values as categorical.\n",
        "\n",
        "    Returns:\n",
        "    cat_cols (list): List of categorical columns.\n",
        "    num_cols (list): List of numerical columns.\n",
        "    cat_but_car (list): List of columns that are categorical but have more than 'car_th' unique values.\n",
        "    num_but_cat (list): List of columns that are numerical but have fewer than 'cat_th' unique values.\n",
        "    \"\"\"\n",
        "\n",
        "    # Identify categorical columns (those with object type)\n",
        "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtype == \"O\"]\n",
        "\n",
        "    # Identify numerical columns with fewer unique values (treated as categorical)\n",
        "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtype != \"O\"]\n",
        "\n",
        "    # Identify categorical columns with more than 'car_th' unique values (treated as cardinal)\n",
        "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtype == \"O\"]\n",
        "\n",
        "    # Merge regular categorical columns with those identified as numerical but categorical\n",
        "    cat_cols = list(set(cat_cols + num_but_cat) - set(cat_but_car))  # Remove columns that are categorical but cardinal\n",
        "\n",
        "    # Identify numerical columns excluding those that are treated as categorical\n",
        "    num_cols = [col for col in dataframe.columns if dataframe[col].dtype != \"O\" and col not in num_but_cat]\n",
        "\n",
        "    # Summary statistics\n",
        "    print(f\"Observations: {dataframe.shape[0]}\")\n",
        "    print(f\"Variables: {dataframe.shape[1]}\")\n",
        "    print(f\"Categorical Columns (cat_cols): {len(cat_cols)}\")\n",
        "    print(f\"Numerical Columns (num_cols): {len(num_cols)}\")\n",
        "    print(f\"Categorical but Cardinal (cat_but_car): {len(cat_but_car)}\")\n",
        "    print(f\"Numerical but Categorical (num_but_cat): {len(num_but_cat)}\")\n",
        "\n",
        "    return cat_cols, num_cols, cat_but_car, num_but_cat"
      ],
      "metadata": {
        "id": "ECJKNZRfiP6E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variable Classification Results ðŸ“Š\n",
        "\n",
        "After running the function **`grab_col_names(df)`**, we have classified the columns in the dataset into different categories based on their data types and the number of unique values they contain. Here's a summary of the classification results:\n",
        "\n",
        "- **Observations**: The dataset contains a total of 768 observations (rows).\n",
        "- **Variables**: The dataset has 9 variables (columns).\n",
        "\n",
        "### Classification of Variables:\n",
        "\n",
        "1. **Categorical Columns (cat_cols)**:\n",
        "   - **Count**: 1\n",
        "   - These are columns where the values represent categories or groups. In our dataset, only one column is identified as categorical.\n",
        "\n",
        "2. **Numerical Columns (num_cols)**:\n",
        "   - **Count**: 8\n",
        "   - These columns contain numerical values, representing measurable quantities. Our dataset has 8 numerical variables, which are essential for statistical analysis and machine learning.\n",
        "\n",
        "3. **Categorical but Cardinal (cat_but_car)**:\n",
        "   - **Count**: 0\n",
        "   - There are no categorical columns that have more than 20 unique values. Typically, these columns would require special handling (e.g., they could be treated as cardinal variables with unique values).\n",
        "\n",
        "4. **Numerical but Categorical (num_but_cat)**:\n",
        "   - **Count**: 1\n",
        "   - This category contains variables that are numerical in type but have a limited number of unique values. In our case, one numerical column is treated as categorical due to its limited range of unique values."
      ],
      "metadata": {
        "id": "v_t1BLFXiaKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols, num_cols, cat_but_car, num_but_cat = grab_col_names(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58IN4V7kiaSQ",
        "outputId": "7971f7db-95be-430d-8cbf-eb291f223688"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observations: 768\n",
            "Variables: 9\n",
            "Categorical Columns (cat_cols): 1\n",
            "Numerical Columns (num_cols): 8\n",
            "Categorical but Cardinal (cat_but_car): 0\n",
            "Numerical but Categorical (num_but_cat): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on this classification, we can proceed with appropriate data preprocessing steps. For instance, categorical columns may need encoding, while numerical columns may require scaling or normalization. Additionally, understanding how many columns belong to each type helps in choosing the right machine learning models and strategies for feature engineering."
      ],
      "metadata": {
        "id": "jUbPczPEicqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function has identified the following column as categorical:\n",
        "\n",
        "- **`Outcome`**: This column represents the target variable in the dataset, indicating whether a patient has diabetes or not. It contains two possible values: `1` (diabetic) and `0` (non-diabetic). Despite being a numerical column (with values 0 and 1), it is treated as categorical because it represents a classification or group, rather than a continuous quantity.\n",
        "\n",
        "Although the `Outcome` column contains numeric values (0 and 1), it is a **binary classification variable**, making it a categorical feature. It does not represent a continuous range of values, but rather two distinct categories or classes, which is why it is categorized as a **categorical variable** in this dataset."
      ],
      "metadata": {
        "id": "fo52WIa3kTDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_JZJ6kSidPW",
        "outputId": "e47f4981-fcf5-478d-956f-c10df8390577"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Outcome']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function has identified the following columns as numerical:\n",
        "\n",
        "- **`Pregnancies`**: The number of pregnancies a patient has had.\n",
        "- **`Glucose`**: The 2-hour plasma glucose concentration during an oral glucose tolerance test.\n",
        "- **`BloodPressure`**: The blood pressure value (measured in mm Hg).\n",
        "- **`SkinThickness`**: The thickness of the skin at the triceps (in mm).\n",
        "- **`Insulin`**: The 2-hour serum insulin level (in ÂµU/ml).\n",
        "- **`BMI`**: The Body Mass Index (BMI) of the patient.\n",
        "- **`DiabetesPedigreeFunction`**: A function that represents the genetic relationship of the patient to diabetes.\n",
        "- **`Age`**: The age of the patient (in years).\n",
        "\n",
        "These columns represent quantitative data and contain continuous or discrete numeric values. They measure variables such as glucose levels, blood pressure, BMI, and age, all of which are essential for making predictions in machine learning models. These numerical columns will be used for statistical analysis and model training in the next steps of the project.\n"
      ],
      "metadata": {
        "id": "QVmpj6dpkIC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICdhioSNkIM3",
        "outputId": "63e28ad5-21e9-41c4-aa38-4c6930c03636"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pregnancies',\n",
              " 'Glucose',\n",
              " 'BloodPressure',\n",
              " 'SkinThickness',\n",
              " 'Insulin',\n",
              " 'BMI',\n",
              " 'DiabetesPedigreeFunction',\n",
              " 'Age']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No columns have been identified as **Categorical but Cardinal (cat_but_car)** in this dataset.\n",
        "\n",
        "**Categorical but Cardinal** refers to categorical variables that contain a large number of unique values (typically more than 20), which would require special handling due to their complexity. These variables are usually not suitable for one-hot encoding and might need to be treated as numerical variables or aggregated into fewer categories.\n",
        "\n",
        "Since no columns fall into this category, we can proceed with handling categorical variables in the usual manner, such as encoding the `Outcome` variable."
      ],
      "metadata": {
        "id": "0Gh1TRrlkJjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_but_car"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itZPrYsAkJu_",
        "outputId": "e4030bbd-5cfc-47a4-db5a-dd6d4db3f5a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following column has been identified as **Numerical but Categorical (num_but_cat)**:\n",
        "\n",
        "- **`Outcome`**: This is the target variable of the dataset, indicating whether a patient has diabetes (`1`) or not (`0`).\n",
        "\n",
        "While the `Outcome` column contains numeric values (0 and 1), it is treated as categorical because it represents a binary classification, not a continuous quantity. The values (0 and 1) signify two distinct categories (diabetic vs. non-diabetic), making it a categorical feature despite being numeric. This column is used for classification tasks, so it is classified as **Numerical but Categorical**.\n",
        "\n",
        "In this case, the column is treated numerically for modeling purposes but conceptually remains categorical."
      ],
      "metadata": {
        "id": "gT0qAxaVkNbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_but_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl84BmYmkNkf",
        "outputId": "fbbf522e-7e19-4f99-c96d-2a1aa3543543"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Outcome']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k_nddFy_k-Q-"
      }
    }
  ]
}